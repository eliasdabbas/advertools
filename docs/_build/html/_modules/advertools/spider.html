

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>advertools.spider &mdash;  Python</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> advertools
          

          
          </a>

          
            
            
              <div class="version">
                0.10.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../readme.html">About advertools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.kw_generate.html">Generate SEM Keywords</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.ad_create.html">Create Text Ads on a Large Scale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.ad_from_string.html">Create Text Ads From Description Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.emoji.html">Emoji Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.extract.html">Extract Structured Entities from Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.sitemaps.html">XML Sitemaps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.stopwords.html">Stop Words</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.word_frequency.html">Text Analysis (absolute &amp; weighted word frequency)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.word_tokenize.html">Word Tokenization (N-grams)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.serp.html">Analyze Search Engine Results (SERPs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.spider.html">SEO Spider / Crawler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.twitter.html">Twitter Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advertools.youtube.html">YouTube Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../include_changelog.html">Index &amp; Change Log</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">advertools</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>advertools.spider</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for advertools.spider</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Python SEO Crawler / Spider</span>
<span class="sd">===========================</span>

<span class="sd">A straightforward crawler to analyze SEO and content of pages and websites.</span>

<span class="sd">This is provided by the :func:`crawl` function which is customized for SEO and</span>
<span class="sd">content analysis usage, and is highly configurable. The crawler uses</span>
<span class="sd">`Scrapy &lt;https://scrapy.org/&gt;`_ so you get all the power that it provides in</span>
<span class="sd">terms of performance, speed, as well as flexibility and customization.</span>

<span class="sd">There are two main approaches to crawl:</span>

<span class="sd">1. **Discovery:** You know the website to crawl, so you provide a ``url_list``</span>
<span class="sd">   (one or more URLs), and you want the crawler to go through the whole</span>
<span class="sd">   website(s) by following all available links.</span>

<span class="sd">2. **Pre-determined:** You have a known set of URLs that you want to crawl and</span>
<span class="sd">   analyze, without following links or discovering new URLs.</span>

<span class="sd">Discovery</span>
<span class="sd">^^^^^^^^^</span>

<span class="sd">The simplest way to use the function is to provide a list of one or more URLs</span>
<span class="sd">and the crawler will go through all of the reachable pages.</span>

<span class="sd">.. code-block:: python</span>

<span class="sd">   &gt;&gt;&gt; crawl(&#39;https://example.com&#39;, &#39;my_output_file.csv&#39;, follow_links=True)</span>

<span class="sd">That&#39;s it!</span>

<span class="sd">What this does:</span>

<span class="sd">* Check the site&#39;s robots.txt file and get the crawl rules</span>
<span class="sd">* Starting with the provided URL(s) go through all links and parse pages</span>
<span class="sd">* For each URL extract the most important SEO elements</span>
<span class="sd">* Save them to ``output_file`` in the specified format</span>
<span class="sd">* The column headers of the output file (if you specify csv) would be the names</span>
<span class="sd">  of the elements</span>

<span class="sd">Supported file extensions:</span>

<span class="sd">* csv</span>
<span class="sd">* json</span>
<span class="sd">* jl</span>
<span class="sd">* xml</span>
<span class="sd">* marshal</span>
<span class="sd">* pickle</span>


<span class="sd">Extracted On-Page SEO Elements</span>
<span class="sd">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>
<span class="sd">The names of these elements become the headers (column names) of the</span>
<span class="sd">``output_file``.</span>

<span class="sd">================= =============================================================</span>
<span class="sd">Element           Remarks</span>
<span class="sd">================= =============================================================</span>
<span class="sd">url               The URL requested</span>
<span class="sd">url_redirected_to The actual URL that was parsed, usually but not always the</span>
<span class="sd">                  same as `url`</span>
<span class="sd">title             The &lt;title&gt; tag(s)</span>
<span class="sd">meta_desc         Meta description</span>
<span class="sd">h1                `&lt;h1&gt;` tag(s)</span>
<span class="sd">h2                `&lt;h2&gt;` tag(s)</span>
<span class="sd">h3                `&lt;h3&gt;` tag(s)</span>
<span class="sd">body_text         The text in the &lt;p&gt; tags</span>
<span class="sd">size              The page size in bytes</span>
<span class="sd">resp_meta_*       Several metadata for the response download_latency, timeout</span>
<span class="sd">                  etc.</span>
<span class="sd">status            Response status (200, 301, 302, 404, etc.)</span>
<span class="sd">links_url         The URLs of the links on the page</span>
<span class="sd">links_text        The link text (anchor text)</span>
<span class="sd">links_fragment    The fragment part of the link (#fragment)</span>
<span class="sd">links_nofollow    Boolean, whether or not the link is a nofllow link</span>
<span class="sd">img_src           The ``src`` attribute of images</span>
<span class="sd">img_alt           The ``alt`` attribute if available or an empty string</span>
<span class="sd">page_depth        The depth of the crawled page</span>
<span class="sd">ip_address        IP address</span>
<span class="sd">crawl_time        Date and time the page was crawled</span>
<span class="sd">resp_headers_*    All available response headers (last modified, server, etc.)</span>
<span class="sd">request_headers_* All available request headers (user-agent, encoding, etc.)</span>
<span class="sd">================= =============================================================</span>

<span class="sd">.. note::</span>

<span class="sd">    All elements that may appear multiple times on a page (like header tags, or</span>
<span class="sd">    images, for example), will be joined with two &quot;@&quot; signs `@@`. For example,</span>
<span class="sd">    **&quot;first H2 tag@@second H2 tag@@third tag&quot;** and so on.</span>
<span class="sd">    Once you open the file, you simply have to split by `@@` to get the</span>
<span class="sd">    elements as a list.</span>

<span class="sd">Here is a sample file of a crawl of this site (output truncated for</span>
<span class="sd">readability):</span>

<span class="sd">.. code-block:: python</span>

<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; site_crawl = pd.read_csv(&#39;path/to/file.csv&#39;)</span>
<span class="sd">    &gt;&gt;&gt; site_crawl.head()</span>
<span class="sd">                                   url               url_redirected_to                           title                       meta_desc                              h1                              h2                              h3                        body_text  size  download_timeout              download_slot  download_latency  redirect_times  redirect_ttl                   redirect_urls redirect_reasons  depth  status                      links_href                      links_text                         img_src                         img_alt    ip_address           crawl_time              resp_headers_date resp_headers_content-type     resp_headers_last-modified resp_headers_vary    resp_headers_x-ms-request-id resp_headers_x-ms-version resp_headers_x-ms-lease-status resp_headers_x-ms-blob-type resp_headers_access-control-allow-origin   resp_headers_x-served resp_headers_x-backend resp_headers_x-rtd-project resp_headers_x-rtd-version         resp_headers_x-rtd-path  resp_headers_x-rtd-domain resp_headers_x-rtd-version-method resp_headers_x-rtd-project-method resp_headers_strict-transport-security resp_headers_cf-cache-status  resp_headers_age           resp_headers_expires resp_headers_cache-control          resp_headers_expect-ct resp_headers_server   resp_headers_cf-ray      resp_headers_cf-request-id          request_headers_accept request_headers_accept-language      request_headers_user-agent request_headers_accept-encoding          request_headers_cookie</span>
<span class="sd">    0   https://advertools.readthedocs  https://advertools.readthedocs            advertools —  Python  Get productive as an online ma  advertools@@Indices and tables  Online marketing productivity                              NaN   Generate keywords for SEM camp   NaN               NaN  advertools.readthedocs.io               NaN             NaN           NaN  https://advertools.readthedocs            [302]    NaN     NaN  #@@readme.html@@advertools.kw_  @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                             NaN                             NaN  104.17.32.82  2020-05-21 10:39:35  Thu, 21 May 2020 10:39:35 GMT                 text/html  Wed, 20 May 2020 12:26:23 GMT   Accept-Encoding  720a8581-501e-0043-01a2-2e77d2                2009-09-19                       unlocked                   BlockBlob                                        *  Nginx-Proxito-Sendfile              web00007c                 advertools                     master  /proxito/media/html/advertools  advertools.readthedocs.io                              path                         subdomain         max-age=31536000; includeSubDo                          HIT               NaN  Thu, 21 May 2020 11:39:35 GMT       public, max-age=3600  max-age=604800, report-uri=&quot;ht          cloudflare  596daca7dbaa7e9e-BUD  02d86a3cea00007e9edb0cf2000000  text/html,application/xhtml+xm                              en  Mozilla/5.0 (Windows NT 10.0;                    gzip, deflate  __cfduid=d76b68d148ddec1efd004</span>
<span class="sd">    1   https://advertools.readthedocs  https://advertools.readthedocs            advertools —  Python                             NaN                      advertools         Change Log - advertools  0.9.1 (2020-05-19)@@0.9.0 (202   Ability to specify robots.txt    NaN               NaN  advertools.readthedocs.io               NaN             NaN           NaN                             NaN              NaN    NaN     NaN  index.html@@readme.html@@adver  @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                             NaN                             NaN  104.17.32.82  2020-05-21 10:39:36  Thu, 21 May 2020 10:39:35 GMT                 text/html  Wed, 20 May 2020 12:26:23 GMT   Accept-Encoding  4f7bea3b-701e-0039-3f44-2f1d9f                2009-09-19                       unlocked                   BlockBlob                                        *  Nginx-Proxito-Sendfile              web00007h                 advertools                     master  /proxito/media/html/advertools  advertools.readthedocs.io                              path                         subdomain         max-age=31536000; includeSubDo                          HIT               NaN  Thu, 21 May 2020 11:39:35 GMT       public, max-age=3600  max-age=604800, report-uri=&quot;ht          cloudflare  596daca9bcab7e9e-BUD  02d86a3e0e00007e9edb0d72000000  text/html,application/xhtml+xm                              en  Mozilla/5.0 (Windows NT 10.0;                    gzip, deflate  __cfduid=d76b68d148ddec1efd004</span>
<span class="sd">    2   https://advertools.readthedocs  https://advertools.readthedocs            advertools —  Python  Get productive as an online ma  advertools@@Indices and tables  Online marketing productivity                              NaN   Generate keywords for SEM camp   NaN               NaN  advertools.readthedocs.io               NaN             NaN           NaN                             NaN              NaN    NaN     NaN  #@@readme.html@@advertools.kw_  @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                             NaN                             NaN  104.17.32.82  2020-05-21 10:39:36  Thu, 21 May 2020 10:39:35 GMT                 text/html  Wed, 20 May 2020 12:26:36 GMT   Accept-Encoding  98b729fa-e01e-00bf-24c3-2e494d                2009-09-19                       unlocked                   BlockBlob                                        *  Nginx-Proxito-Sendfile              web00007c                 advertools                     latest  /proxito/media/html/advertools  advertools.readthedocs.io                              path                         subdomain         max-age=31536000; includeSubDo                          HIT               NaN  Thu, 21 May 2020 11:39:35 GMT       public, max-age=3600  max-age=604800, report-uri=&quot;ht          cloudflare  596daca9bf26d423-BUD  02d86a3e150000d423322742000000  text/html,application/xhtml+xm                              en  Mozilla/5.0 (Windows NT 10.0;                    gzip, deflate  __cfduid=d76b68d148ddec1efd004</span>
<span class="sd">    3   https://advertools.readthedocs  https://advertools.readthedocs    advertools package —  Python                             NaN              advertools package     Submodules@@Module contents                             NaN   Top-level package for advertoo   NaN               NaN  advertools.readthedocs.io               NaN             NaN           NaN                             NaN              NaN    NaN     NaN  index.html@@readme.html@@adver  @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                             NaN                             NaN  104.17.32.82  2020-05-21 10:39:36  Thu, 21 May 2020 10:39:35 GMT                 text/html  Wed, 20 May 2020 12:26:25 GMT   Accept-Encoding  7a28ef3b-801e-00c2-24c3-2ed585                2009-09-19                       unlocked                   BlockBlob                                        *  Nginx-Proxito-Sendfile              web000079                 advertools                     master  /proxito/media/html/advertools  advertools.readthedocs.io                              path                         subdomain         max-age=31536000; includeSubDo                          HIT               NaN  Thu, 21 May 2020 11:39:35 GMT       public, max-age=3600  max-age=604800, report-uri=&quot;ht          cloudflare  596daca9bddb7ec2-BUD  02d86a3e1300007ec2a808a2000000  text/html,application/xhtml+xm                              en  Mozilla/5.0 (Windows NT 10.0;                    gzip, deflate  __cfduid=d76b68d148ddec1efd004</span>
<span class="sd">    4   https://advertools.readthedocs  https://advertools.readthedocs   Python Module Index —  Python                             NaN             Python Module Index                             NaN                             NaN            © Copyright 2020, Eli   NaN               NaN  advertools.readthedocs.io               NaN             NaN           NaN                             NaN              NaN    NaN     NaN  index.html@@readme.html@@adver  @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@               _static/minus.png                               -  104.17.32.82  2020-05-21 10:39:36  Thu, 21 May 2020 10:39:35 GMT                 text/html  Wed, 20 May 2020 12:26:23 GMT   Accept-Encoding  75911c9e-201e-00e6-34c3-2e4ccb                2009-09-19                       unlocked                   BlockBlob                                        *  Nginx-Proxito-Sendfile              web00007g                 advertools                     master  /proxito/media/html/advertools  advertools.readthedocs.io                              path                         subdomain         max-age=31536000; includeSubDo                          HIT               NaN  Thu, 21 May 2020 11:39:35 GMT       public, max-age=3600  max-age=604800, report-uri=&quot;ht          cloudflare  596daca9b91fd437-BUD  02d86a3e140000d437b81532000000  text/html,application/xhtml+xm                              en  Mozilla/5.0 (Windows NT 10.0;                    gzip, deflate  __cfduid=d76b68d148ddec1efd004</span>
<span class="sd">    66  https://advertools.readthedocs  https://advertools.readthedocs  advertools.url_builders —  Pyt                             NaN  Source code for advertools.url                             NaN                             NaN            © Copyright 2020, Eli   NaN               NaN  advertools.readthedocs.io               NaN             NaN           NaN                             NaN              NaN    NaN     NaN  ../../index.html@@../../readme  @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                             NaN                             NaN  104.17.32.82  2020-05-21 10:39:39  Thu, 21 May 2020 10:39:38 GMT                 text/html  Wed, 20 May 2020 12:26:36 GMT   Accept-Encoding  d99f2368-c01e-006f-18c3-2ef5ef                2009-09-19                       unlocked                   BlockBlob                                        *  Nginx-Proxito-Sendfile              web00007a                 advertools                     latest  /proxito/media/html/advertools  advertools.readthedocs.io                              path                         subdomain         max-age=31536000; includeSubDo                          HIT               NaN  Thu, 21 May 2020 11:39:38 GMT       public, max-age=3600  max-age=604800, report-uri=&quot;ht          cloudflare  596dacbbb8afd437-BUD  02d86a494f0000d437b828b2000000  text/html,application/xhtml+xm                              en  Mozilla/5.0 (Windows NT 10.0;                    gzip, deflate  __cfduid=d76b68d148ddec1efd004</span>
<span class="sd">    67  https://advertools.readthedocs  https://advertools.readthedocs  advertools.kw_generate —  Pyth                             NaN  Source code for advertools.kw_                             NaN                             NaN            © Copyright 2020, Eli   NaN               NaN  advertools.readthedocs.io               NaN             NaN           NaN                             NaN              NaN    NaN     NaN  ../../index.html@@../../readme  @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                             NaN                             NaN  104.17.32.82  2020-05-21 10:39:39  Thu, 21 May 2020 10:39:39 GMT                 text/html  Wed, 20 May 2020 12:26:36 GMT   Accept-Encoding  85855c48-c01e-00ce-13c3-2e3b74                2009-09-19                       unlocked                   BlockBlob                                        *  Nginx-Proxito-Sendfile              web00007g                 advertools                     latest  /proxito/media/html/advertools  advertools.readthedocs.io                              path                         subdomain         max-age=31536000; includeSubDo                          HIT               NaN  Thu, 21 May 2020 11:39:39 GMT       public, max-age=3600  max-age=604800, report-uri=&quot;ht          cloudflare  596dacbd980bd423-BUD  02d86a4a7f0000d423323b42000000  text/html,application/xhtml+xm                              en  Mozilla/5.0 (Windows NT 10.0;                    gzip, deflate  __cfduid=d76b68d148ddec1efd004</span>
<span class="sd">    68  https://advertools.readthedocs  https://advertools.readthedocs  advertools.ad_from_string —  P                             NaN  Source code for advertools.ad_                             NaN                             NaN            © Copyright 2020, Eli   NaN               NaN  advertools.readthedocs.io               NaN             NaN           NaN                             NaN              NaN    NaN     NaN  ../../index.html@@../../readme  @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                             NaN                             NaN  104.17.32.82  2020-05-21 10:39:39  Thu, 21 May 2020 10:39:39 GMT                 text/html  Wed, 20 May 2020 12:26:36 GMT   Accept-Encoding  b0aef497-801e-004a-1647-2f6d5c                2009-09-19                       unlocked                   BlockBlob                                        *  Nginx-Proxito-Sendfile              web00007k                 advertools                     latest  /proxito/media/html/advertools  advertools.readthedocs.io                              path                         subdomain         max-age=31536000; includeSubDo                          HIT               NaN  Thu, 21 May 2020 11:39:39 GMT       public, max-age=3600  max-age=604800, report-uri=&quot;ht          cloudflare  596dacbd980cd423-BUD  02d86a4a7f0000d423209db2000000  text/html,application/xhtml+xm                              en  Mozilla/5.0 (Windows NT 10.0;                    gzip, deflate  __cfduid=d76b68d148ddec1efd004</span>
<span class="sd">    69  https://advertools.readthedocs  https://advertools.readthedocs  advertools.ad_create —  Python                             NaN  Source code for advertools.ad_                             NaN                             NaN            © Copyright 2020, Eli   NaN               NaN  advertools.readthedocs.io               NaN             NaN           NaN                             NaN              NaN    NaN     NaN  ../../index.html@@../../readme  @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                             NaN                             NaN  104.17.32.82  2020-05-21 10:39:39  Thu, 21 May 2020 10:39:39 GMT                 text/html  Wed, 20 May 2020 12:26:36 GMT   Accept-Encoding  9dfdd38a-101e-00a1-7ec3-2e93a0                2009-09-19                       unlocked                   BlockBlob                                        *  Nginx-Proxito-Sendfile              web00007c                 advertools                     latest  /proxito/media/html/advertools  advertools.readthedocs.io                              path                         subdomain         max-age=31536000; includeSubDo                          HIT               NaN  Thu, 21 May 2020 11:39:39 GMT       public, max-age=3600  max-age=604800, report-uri=&quot;ht          cloudflare  596dacbd99847ec2-BUD  02d86a4a7f00007ec2a811f2000000  text/html,application/xhtml+xm                              en  Mozilla/5.0 (Windows NT 10.0;                    gzip, deflate  __cfduid=d76b68d148ddec1efd004</span>
<span class="sd">    70  https://advertools.readthedocs  https://advertools.readthedocs      advertools.emoji —  Python                             NaN  Source code for advertools.emo                             NaN                             NaN            © Copyright 2020, Eli   NaN               NaN  advertools.readthedocs.io               NaN             NaN           NaN                             NaN              NaN    NaN     NaN  ../../index.html@@../../readme  @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                             NaN                             NaN  104.17.32.82  2020-05-21 10:39:40  Thu, 21 May 2020 10:39:39 GMT                 text/html  Wed, 20 May 2020 12:26:36 GMT   Accept-Encoding  2ad504a1-101e-000b-03c3-2e454f                2009-09-19                       unlocked                   BlockBlob                                        *  Nginx-Proxito-Sendfile              web000079                 advertools                     latest  /proxito/media/html/advertools  advertools.readthedocs.io                              path                         subdomain         max-age=31536000; includeSubDo                          HIT               NaN  Thu, 21 May 2020 11:39:39 GMT       public, max-age=3600  max-age=604800, report-uri=&quot;ht          cloudflare  596dacbd9fb97e9e-BUD  02d86a4a7f00007e9edb13a2000000  text/html,application/xhtml+xm                              en  Mozilla/5.0 (Windows NT 10.0;                    gzip, deflate  __cfduid=d76b68d148ddec1efd004</span>

<span class="sd">Pre-Determined Crawling Approach</span>
<span class="sd">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>

<span class="sd">Sometimes you might have a fixed set of URLs for which you want to scrape and</span>
<span class="sd">analyze SEO or content performance. Some ideas:</span>

<span class="sd">SERP Data</span>
<span class="sd">---------</span>
<span class="sd">Let&#39;s say you just ran :ref:`serp_goog &lt;serp&gt;` and got a bunch of top-ranking</span>
<span class="sd">pages that you would like to analyze, and see how that relates to their SERP</span>
<span class="sd">ranking.</span>

<span class="sd">You simply provide the ``url_list`` parameter and again specify the</span>
<span class="sd">``output_file``. This will only crawl the specified URLs, and will not follow</span>
<span class="sd">any links.</span>

<span class="sd">Now you have the SERP DataFrame, as well as the crawl output file. All you have</span>
<span class="sd">to do is to merge them by the URL columns, and end up with a richer dataset</span>

<span class="sd">News Articles</span>
<span class="sd">-------------</span>
<span class="sd">You want to follow the latest news of a certain publication, and you extract</span>
<span class="sd">their latest news URLs from their news sitemap using</span>
<span class="sd">:ref:`sitemap_to_df &lt;sitemaps&gt;` . You provide those URLs and crawl them only.</span>

<span class="sd">Google Analytics / Google Search Console</span>
<span class="sd">----------------------------------------</span>
<span class="sd">Since they provide reports for URLs, you can also combine them with the ones</span>
<span class="sd">crawled and end up with a better perspective. You might be interested in</span>
<span class="sd">knowing more about high bounce-rate pages, pages that convert well, pages that</span>
<span class="sd">get less traffic than you think they should and so on. You can simply export</span>
<span class="sd">those URLs and crawl them.</span>

<span class="sd">Any tool that has data about a set of URLs can be used.</span>

<span class="sd">Again running the function is as simple as providing a list of URLs, as well as</span>
<span class="sd">a filepath where you want the result saved.</span>

<span class="sd">.. code-block:: python</span>

<span class="sd">    &gt;&gt;&gt; crawl(url_list, output_file, follow_links=False)</span>

<span class="sd">The difference between the two approaches, is the simple parameter</span>
<span class="sd">``follow_links``. If you keep it as ``False`` (the default), the crawler</span>
<span class="sd">will only go through the provided URLs. Otherwise, it will discover pages by</span>
<span class="sd">following links on pages that it crawls. So how do you make sure that the</span>
<span class="sd">crawler doesn&#39;t try to crawl the whole web when ``follow_links`` is `True`?</span>
<span class="sd">The ``allowed_domains`` parameter gives you the ability to control this,</span>
<span class="sd">although it is and optional parameter. If you don&#39;t specify it, then it will</span>
<span class="sd">default to only the domains in the ``url_list``.</span>

<span class="sd">CSS and XPath Selectors</span>
<span class="sd">^^^^^^^^^^^^^^^^^^^^^^^</span>

<span class="sd">The above approaches are generic, and are useful for an exploratory SEO audit</span>
<span class="sd">and the output is helpful for most cases.</span>

<span class="sd">But what if you want to extract special elements that are not included in the</span>
<span class="sd">default output? This is extremely important, as there are key elements on pages</span>
<span class="sd">that you need to additionally extract and analyze. Some examples might be tags,</span>
<span class="sd">prices, social media shares, product price or availability, comments, and</span>
<span class="sd">pretty much any element on a page that might be of interest to you.</span>

<span class="sd">For this you can use two special arguments for CSS and/or XPath selectors. You</span>
<span class="sd">simply provide a dictionary `{&#39;name_1&#39;: &#39;selector_1&#39;, &#39;name_2&#39;: &#39;selector_2&#39;}`</span>
<span class="sd">where the keys become the column names, and the values (selectors) will be</span>
<span class="sd">used to extract the required elements.</span>

<span class="sd">I mostly rely on `SlectorGadget &lt;https://selectorgadget.com/&gt;`_ which is a</span>
<span class="sd">really great tool for getting the CSS/XPath selecotrs of required elements.</span>
<span class="sd">In some pages it can get really tricky to figure that out. Other resources for</span>
<span class="sd">learning more about selectors:</span>

<span class="sd">* `Scrapy&#39;s documentaion for selectors &lt;https://docs.scrapy.org/en/latest/topics/selectors.html&gt;`_</span>
<span class="sd">* `CSS Selector Reference on W3C &lt;https://www.w3schools.com/cssref/css_selectors.asp&gt;`_</span>
<span class="sd">* `XPath tutorial on W3C &lt;https://www.w3schools.com/xml/xpath_intro.asp&gt;`_</span>

<span class="sd">Once you have determined the elements that you want to extract and figured out</span>
<span class="sd">what their names are going to be, you simply pass them as arguments to</span>
<span class="sd">``css_selectors`` and/or ``xpath_selectors`` as dictionaries, as decribed</span>
<span class="sd">above.</span>

<span class="sd">Let&#39;s say you want to extract the links in the sidebar of this page. By default</span>
<span class="sd">you would get all the links from the page, but you want to put those in the</span>
<span class="sd">sidebar in a separate column. It seems that the CSS selector for them is</span>
<span class="sd">`.toctree-l1 .internal`, and the XPath equivalent is</span>
<span class="sd">`//*[contains(concat( &quot; &quot;, @class, &quot; &quot; ), concat( &quot; &quot;, &quot;toctree-l1&quot;, &quot; &quot; ))]//*[contains(concat( &quot; &quot;, @class, &quot; &quot; ), concat( &quot; &quot;, &quot;internal&quot;, &quot; &quot; ))]`.</span>
<span class="sd">Note that this selects the *element* (the whole link object), which is not</span>
<span class="sd">typically what you might be interested in.</span>

<span class="sd">So with CSS you need to append `::text` or `::attr(href)` if you want the text of</span>
<span class="sd">the links or the `href` attribute respectively. Similarly with XPath, you will</span>
<span class="sd">need to append `/text()` or `/@href` to the selector to get the same.</span>

<span class="sd">&gt;&gt;&gt; crawl(&#39;https://advertools.readthedocs.io/en/master/advertools.spider.html&#39;,</span>
<span class="sd">...       &#39;output_file.csv&#39;,</span>
<span class="sd">...       css_selectors={&#39;sidebar_links&#39;: &#39;.toctree-l1 .internal::text&#39;,</span>
<span class="sd">...                      &#39;sidebar_links_url&#39;: &#39;.toctree-l1 .internal::attr(href)&#39;})</span>

<span class="sd">Or, instead of ``css_selectors`` you can add a similar dictionary for the</span>
<span class="sd">``xpath_selectors`` argument:</span>

<span class="sd">&gt;&gt;&gt; crawl(&#39;https://advertools.readthedocs.io/en/master/advertools.spider.html&#39;,</span>
<span class="sd">...       &#39;output_file.csv&#39;,</span>
<span class="sd">...       xpath_selectors={&#39;sidebar_links&#39;: &#39;//*[contains(concat( &quot; &quot;, @class, &quot; &quot; ), concat( &quot; &quot;, &quot;toctree-l1&quot;, &quot; &quot; ))]//*[contains(concat( &quot; &quot;, @class, &quot; &quot; ), concat( &quot; &quot;, &quot;internal&quot;, &quot; &quot; ))]/text()&#39;,</span>
<span class="sd">...                        &#39;sidebar_links_url&#39;: &#39;//*[contains(concat( &quot; &quot;, @class, &quot; &quot; ), concat( &quot; &quot;, &quot;toctree-l1&quot;, &quot; &quot; ))]//*[contains(concat( &quot; &quot;, @class, &quot; &quot; ), concat( &quot; &quot;, &quot;internal&quot;, &quot; &quot; ))]/@href&#39;})</span>

<span class="sd">Spider Custom Settings and Additional Functionality</span>
<span class="sd">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>

<span class="sd">In addition to what you can control regarding the items you can extract, you</span>
<span class="sd">can also customize the behaviour of the spider and set rules for crawling so</span>
<span class="sd">you can control it even further.</span>

<span class="sd">This is provided by the ``custom_settings`` parameter. It is optional, and</span>
<span class="sd">takes a dictionary of settings and their values. Scrapy provides a very large</span>
<span class="sd">number of settings, and they are all available through this parameter</span>
<span class="sd">(assuming some conditions for some of the settings).</span>

<span class="sd">Here are some examples that you might find interesting:</span>

<span class="sd">* `CONCURRENT_REQUESTS_PER_DOMAIN` Defaults to 8, and controls the number of</span>
<span class="sd">  simultaneous requests to be performed for each domain. You might want to</span>
<span class="sd">  lower this if you don&#39;t want to put too much pressure on the website&#39;s</span>
<span class="sd">  server, and you probably don&#39;t want to get blocked!</span>
<span class="sd">* `DEFAULT_REQUEST_HEADERS` You can change this if you need to.</span>
<span class="sd">* `DEPTH_LIMIT` How deep your crawl will be allowed. The default has no limit.</span>
<span class="sd">* `DOWNLOAD_DELAY` Similar to the first option. Controls the amount of time in</span>
<span class="sd">  seconds for the crawler to wait between consecutive pages of the same website.</span>
<span class="sd">  It can also take fractions of a second (0.4, 0.75, etc.)</span>
<span class="sd">* `LOG_FILE` If you want to save your crawl logs to a file, you can provide a</span>
<span class="sd">  path to it here.</span>
<span class="sd">* `USER_AGENT` If you want to identify yourself differently while crawling.</span>
<span class="sd">* `CLOSESPIDER_ERRORCOUNT`, `CLOSESPIDER_ITEMCOUNT`, `CLOSESPIDER_PAGECOUNT`,</span>
<span class="sd">  `CLOSESPIDER_TIMEOUT` Stop crawling after that many errors, items, pages, or</span>
<span class="sd">  seconds. These can be very useful to limit your crawling in certain cases.</span>
<span class="sd">  I particularly like to use `CLOSESPIDER_PAGECOUNT` when exploring a new</span>
<span class="sd">  website, and also to make sure that my selectors are working as expected. So</span>
<span class="sd">  for your first few crawls you might set this to one hundred for example and</span>
<span class="sd">  explore the crawled pages. Then when you are confident things are working</span>
<span class="sd">  fine, you can remove this restriction. `CLOSESPIDER_ERRORCOUNT` can also be</span>
<span class="sd">  very useful while exploring, just in case you get unexpected errors.</span>

<span class="sd">**Usage**</span>

<span class="sd">A very simpl dictionary to be added to your function call:</span>

<span class="sd">&gt;&gt;&gt; crawl(&#39;http://exmaple.com&#39;, &#39;outpuf_file.csv&#39;,</span>
<span class="sd">...       custom_settings={&#39;CLOSESPIDER_PAGECOUNT&#39;: 100,</span>
<span class="sd">...                        &#39;CONCURRENT_REQUESTS_PER_DOMAIN&#39;: 1,</span>
<span class="sd">...                        &#39;USER_AGENT&#39;: &#39;custom-user-agent&#39;})</span>

<span class="sd">Please refer to the `spider settings documentation &lt;https://docs.scrapy.org/en/latest/topics/settings.html&gt;`_</span>
<span class="sd">for the full details.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">subprocess</span>

<span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="k">import</span> <span class="n">urlparse</span>

<span class="kn">from</span> <span class="nn">scrapy.spiders</span> <span class="k">import</span> <span class="n">Spider</span>
<span class="kn">from</span> <span class="nn">scrapy.linkextractors</span> <span class="k">import</span> <span class="n">LinkExtractor</span>
<span class="kn">from</span> <span class="nn">scrapy</span> <span class="k">import</span> <span class="n">Request</span>
<span class="kn">import</span> <span class="nn">advertools</span> <span class="k">as</span> <span class="nn">adv</span>

<span class="n">spider_path</span> <span class="o">=</span> <span class="n">adv</span><span class="o">.</span><span class="n">__path__</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;/spider.py&#39;</span>

<span class="n">user_agent</span> <span class="o">=</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 &#39;</span> \
             <span class="s1">&#39;(KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36&#39;</span><span class="p">,</span>

<span class="n">BODY_TEXT_SELECTOR</span> <span class="o">=</span> <span class="s1">&#39;//body//span//text() | //body//p//text() | //body//li//text()&#39;</span>

<span class="n">le</span> <span class="o">=</span> <span class="n">LinkExtractor</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">SEOSitemapSpider</span><span class="p">(</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;seo_sitemap_spider&#39;</span>
    <span class="n">follow_links</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">css_selectors</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">xpath_selectors</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">custom_settings</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;USER_AGENT&#39;</span><span class="p">:</span> <span class="n">user_agent</span><span class="p">,</span>
        <span class="s1">&#39;ROBOTSTXT_OBEY&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;HTTPERROR_ALLOW_ALL&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">allowed_domains</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">css_selectors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xpath_selectors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">follow_links</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_urls</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">url_list</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allowed_domains</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">allowed_domains</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">follow_links</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">follow_links</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">css_selectors</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">css_selectors</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xpath_selectors</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">xpath_selectors</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">links</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">extract_links</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">css_selectors</span><span class="p">:</span>
            <span class="n">css_selectors</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="s1">&#39;@@&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">val</span><span class="p">))</span><span class="o">.</span><span class="n">getall</span><span class="p">())</span>
                             <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">css_selectors</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">css_selectors</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpath_selectors</span><span class="p">:</span>
            <span class="n">xpath_selectors</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="s1">&#39;@@&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">val</span><span class="p">))</span><span class="o">.</span><span class="n">getall</span><span class="p">())</span>
                               <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpath_selectors</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xpath_selectors</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">yield</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">url</span><span class="p">,</span>
            <span class="n">url_redirected_to</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">,</span>
            <span class="n">title</span><span class="o">=</span><span class="s1">&#39;@@&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;title::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()),</span>
            <span class="n">meta_desc</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s2">&quot;//meta[@name=&#39;description&#39;]/@content&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
            <span class="n">h1</span><span class="o">=</span><span class="s1">&#39;@@&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;h1::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()),</span>
            <span class="n">h2</span><span class="o">=</span><span class="s1">&#39;@@&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;h2::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()),</span>
            <span class="n">h3</span><span class="o">=</span><span class="s1">&#39;@@&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;h3::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()),</span>
            <span class="n">body_text</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="n">BODY_TEXT_SELECTOR</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()),</span>
            <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">),</span>
            <span class="o">**</span><span class="n">css_selectors</span><span class="p">,</span>
            <span class="o">**</span><span class="n">xpath_selectors</span><span class="p">,</span>
            <span class="o">**</span><span class="p">{</span><span class="s1">&#39;resp_meta_&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">:</span> <span class="n">v</span>
               <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
            <span class="n">status</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">status</span><span class="p">,</span>
            <span class="n">links_url</span><span class="o">=</span><span class="s1">&#39;@@&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">link</span><span class="o">.</span><span class="n">url</span> <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">),</span>
            <span class="n">links_text</span><span class="o">=</span><span class="s1">&#39;@@&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">link</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">),</span>
            <span class="n">links_fragment</span><span class="o">=</span><span class="s1">&#39;@@&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">link</span><span class="o">.</span><span class="n">fragment</span> <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">),</span>
            <span class="n">links_nofollow</span><span class="o">=</span><span class="s1">&#39;@@&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">link</span><span class="o">.</span><span class="n">nofollow</span><span class="p">)</span> <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">),</span>
            <span class="n">img_src</span><span class="o">=</span><span class="s1">&#39;@@&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">im</span><span class="o">.</span><span class="n">attrib</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;src&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="s1">&#39;&#39;</span>
                               <span class="k">for</span> <span class="n">im</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;img&#39;</span><span class="p">)]),</span>
            <span class="n">img_alt</span><span class="o">=</span><span class="s1">&#39;@@&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">im</span><span class="o">.</span><span class="n">attrib</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;alt&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="s1">&#39;&#39;</span>
                               <span class="k">for</span> <span class="n">im</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;img&#39;</span><span class="p">)]),</span>
            <span class="n">ip_address</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">ip_address</span><span class="p">,</span>
            <span class="n">crawl_time</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1"> %H:%M:%S&#39;</span><span class="p">),</span>
            <span class="o">**</span><span class="p">{</span><span class="s1">&#39;resp_headers_&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">:</span> <span class="n">v</span>
               <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">to_unicode_dict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
            <span class="o">**</span><span class="p">{</span><span class="s1">&#39;request_headers_&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">:</span> <span class="n">v</span>
               <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">to_unicode_dict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">follow_links</span><span class="p">:</span>
            <span class="n">next_pages</span> <span class="o">=</span> <span class="p">[</span><span class="n">link</span><span class="o">.</span><span class="n">url</span> <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">next_pages</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">next_pages</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">Request</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>


<div class="viewcode-block" id="crawl"><a class="viewcode-back" href="../../advertools.spider.html#advertools.spider.crawl">[docs]</a><span class="k">def</span> <span class="nf">crawl</span><span class="p">(</span><span class="n">url_list</span><span class="p">,</span> <span class="n">output_file</span><span class="p">,</span> <span class="n">follow_links</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">css_selectors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">xpath_selectors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">custom_settings</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">allowed_domains</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Crawl a website&#39;s URLs based on the given :attr:`url_list`</span>

<span class="sd">    :param url,list url_list: One or more URLs to crawl. If ``follow_links``</span>
<span class="sd">                          is True, the crawler will start with these URLs and</span>
<span class="sd">                          follow all links on pages recursively.</span>
<span class="sd">    :param str output_file: The path to the output of the crawl. Supported</span>
<span class="sd">                            formats: `csv`, `json`, `jsonlines`, `jl`, `xml`,</span>
<span class="sd">                            `marshal`, `pickle`.</span>
<span class="sd">    :param bool follow_links: Defaults to False. Whether or not to follow links</span>
<span class="sd">                              on crawled pages.</span>
<span class="sd">    :param dict css_selectors: A dictionary mapping names to CSS selectors. The</span>
<span class="sd">                               names will become column headers, and the</span>
<span class="sd">                               selectors will be used to extract the required</span>
<span class="sd">                               data/content.</span>
<span class="sd">    :param dict xpath_selectors: A dictionary mapping names to XPath selectors.</span>
<span class="sd">                                 The names will become column headers, and the</span>
<span class="sd">                                 selectors will be used to extract the required</span>
<span class="sd">                                 data/content.</span>
<span class="sd">    :param dict custom_settings: A dictionary of optional custom settings that</span>
<span class="sd">                                 you might want to add to the spider&#39;s</span>
<span class="sd">                                 functionality. There are over 170 settings for</span>
<span class="sd">                                 all kinds of options. For details please</span>
<span class="sd">                                 refer to the `spider settings &lt;https://docs.scrapy.org/en/latest/topics/settings.html&gt;`_</span>
<span class="sd">                                 documentation.</span>
<span class="sd">    :param list allowed_domains: (optional) A list of the allowed domains to</span>
<span class="sd">                                 crawl. This ensures that the crawler does not</span>
<span class="sd">                                 attempt to crawl the whole web. If not</span>
<span class="sd">                                 specified, it defaults to the domains of the</span>
<span class="sd">                                 URLs provided in ``url_list``.</span>
<span class="sd">    :Examples:</span>

<span class="sd">    Crawl a website and let the crawler discover as many pages as available</span>

<span class="sd">    &gt;&gt;&gt; crawl(&#39;http://example.com&#39;, &#39;output_file.csv&#39;, follow_links=True)</span>

<span class="sd">    Crawl a known set of pages (on a single or multiple sites) without</span>
<span class="sd">    following links (just crawl the specified pages):</span>

<span class="sd">    &gt;&gt;&gt; crawl([&#39;http://exmaple.com/product&#39;, &#39;http://exmaple.com/product2&#39;,</span>
<span class="sd">    ...        &#39;https://anotherexample.com&#39;, &#39;https://anotherexmaple.com/hello&#39;],</span>
<span class="sd">    ...        &#39;output_file.csv&#39;, follow_links=False)</span>

<span class="sd">    Crawl a website, and in addition to standard SEO elements, also get the</span>
<span class="sd">    required CSS selectors.</span>
<span class="sd">    Here we will get three additional columns `price`, `author`, and</span>
<span class="sd">    `author_url`. Note that you need to specify if you want the text attribute</span>
<span class="sd">    or the `href` attribute if you are working with links (and all other</span>
<span class="sd">    selectors).</span>

<span class="sd">    &gt;&gt;&gt; crawl(&#39;http://example.com&#39;, &#39;output_file.csv&#39;,</span>
<span class="sd">    ...       css_selectors={&#39;price&#39;: &#39;.a-color-price::text&#39;,</span>
<span class="sd">    ...                      &#39;author&#39;: &#39;.contributorNameID::text&#39;,</span>
<span class="sd">    ...                      &#39;author_url&#39;: &#39;.contributorNameID::attr(href)&#39;})</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">url_list</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">url_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">url_list</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">allowed_domains</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="n">allowed_domains</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">allowed_domains</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">{</span><span class="n">urlparse</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">netloc</span> <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">url_list</span><span class="p">}</span>
    <span class="n">settings_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">custom_settings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">custom_settings</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">setting</span> <span class="o">=</span> <span class="s1">&#39;=&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">val</span><span class="p">)])</span>
            <span class="n">settings_list</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;-s&#39;</span><span class="p">,</span> <span class="n">setting</span><span class="p">])</span>

    <span class="n">command</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;scrapy&#39;</span><span class="p">,</span> <span class="s1">&#39;runspider&#39;</span><span class="p">,</span> <span class="n">spider_path</span><span class="p">,</span>
               <span class="s1">&#39;-a&#39;</span><span class="p">,</span> <span class="s1">&#39;url_list=&#39;</span> <span class="o">+</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">url_list</span><span class="p">),</span>
               <span class="s1">&#39;-a&#39;</span><span class="p">,</span> <span class="s1">&#39;allowed_domains=&#39;</span> <span class="o">+</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">allowed_domains</span><span class="p">),</span>
               <span class="s1">&#39;-a&#39;</span><span class="p">,</span> <span class="s1">&#39;follow_links=&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">follow_links</span><span class="p">),</span>
               <span class="s1">&#39;-a&#39;</span><span class="p">,</span> <span class="s1">&#39;css_selectors=&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">css_selectors</span><span class="p">),</span>
               <span class="s1">&#39;-a&#39;</span><span class="p">,</span> <span class="s1">&#39;xpath_selectors=&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">xpath_selectors</span><span class="p">),</span>
               <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">output_file</span><span class="p">]</span> <span class="o">+</span> <span class="n">settings_list</span>
    <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">command</span><span class="p">)</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Elias Dabbas

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>